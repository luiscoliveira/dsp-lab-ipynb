{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSP Lab 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This lab assignment requires preparation before the lab session. Try to fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" before the session in order to use the limited amount of available time to clarify any doubt or to discuss your solution. Paragraphs that start with ❓explain what you will need to do in the following cell.\n",
    "\n",
    "IMPORTANT: Do not modify the code or text outside the cells with `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Those modifications will be discarded by the automatic grading system and may affect the way it will grade your work.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "This notebook requires an up to date version of IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 8, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6373fab92349478157e3fd9f4cdb1808",
     "grade": false,
     "grade_id": "cell-687f1b166897620c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Lab2 - Music Analysis and Synthesis\n",
    "\n",
    "_Luis Caldas de Oliveira_\n",
    "\n",
    "In the previous lab assignment, we discussed the analysis of stationary (sine and square waves) and quasi-stationary (a single musical note played by a musical instrument) signals. It introduced some tools that help characterize these signals in the time and frequency domains.\n",
    "\n",
    "In this lab assignment, you will work with signals whose characteristics change in time as is a case of a musical piece. You will see that the analysis tools used previously can be applied if we divide a signal into small sections during which we assume that the signal is approximately stationary. The evolution of the characteristics of the signal obtained in this way allows us to extract information about its content such as the sequence of notes and the duration of each one.\n",
    "\n",
    "The application of signal-processing approaches to extract meaningful information from music audio signals is called Music Information Retrieval (MIR), a field of study and research that focuses on the development of systems that can automatically analyze, process, and organize audio or music data.\n",
    "\n",
    "In this assignment you will also go in the other direction, that is, to produce a music audio signal from a higher-level representation. A music synthesizer is a device that uses signal processing techniques to generate an audio signal. In the early years of electronic music, these devices were mostly composed of electronic circuits that generated and modified continuous-time signals, but today, most synthesizers use digital signal processing techniques for that purpose. Synthesizers can be used to create new sounds or to simulate natural sounds such as the ones produced by traditional musical instruments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "897ca643552f0b049df7b04ca12be645",
     "grade": false,
     "grade_id": "cell-b0c1f1a2019d4e77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Group and Student ID\n",
    "\n",
    "#### A01 - Initialize group and student id\n",
    "\n",
    "❓Initialize the variable `group_id` with the number that Fenix assigned to your group and `ist_id1` and `ist_id2` with your student numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5f9b89169ad0b87c7eb1140361fa2a1",
     "grade": false,
     "grade_id": "cell-ddd672772100abac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Group number: {group_id}\")\n",
    "print(f\"Student number: {ist_id1}\")\n",
    "print(f\"Student number: {ist_id2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd74dc7ce90cc3a8e680e334eee195d9",
     "grade": true,
     "grade_id": "cell-45c1a6b38b138c07",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(group_id, int) and isinstance(ist_id1, int) and isinstance(ist_id2, int)\n",
    "assert (group_id > 0) and (group_id < 35)\n",
    "assert (ist_id1 > 60000) and (ist_id1 < 120000) and (ist_id2 > 60000) and (ist_id2 < 120000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85890109614b7cd3624575b744bd6138",
     "grade": false,
     "grade_id": "cell-ac05fb5b3bc2cb81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Group note\n",
    "\n",
    "Remember your group note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7d022fdcc62153e85a119f1c8575c62",
     "grade": false,
     "grade_id": "cell-10d119bc31d9905c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "semitones = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "group_note = semitones[(ist_id1+ist_id2)%12] + str(3+(group_id-3)%4)\n",
    "print(f\"Your group's note is: {group_note}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cadc959ca6da47f53884cc96de71beb1",
     "grade": false,
     "grade_id": "cell-70056cac17313f51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Import libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c48e401d9859d7a3e71e1a5fb91cfca",
     "grade": false,
     "grade_id": "cell-ec7e8f6f922be8be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b9cef76740e994edc446728fc4c7cff",
     "grade": false,
     "grade_id": "cell-e8f7f6311505121c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Note frequency\n",
    "\n",
    "In an equal temperament tuning system there is a relationship between a musical note and it's frequency if a reference pair is provided. The most common reference is to assign the frequency of $440\\ Hz$ to the musical note A4.\n",
    "\n",
    "#### A02 - Create a function to compute a note's frequency\n",
    "\n",
    "❓The function `note_frequency()` computes the frequency of the note. Use only standard Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b462c275a43006a96f60e9a5fea3100",
     "grade": false,
     "grade_id": "cell-3170af02dfa0c7ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def note_frequency(note):\n",
    "    semitones = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return frequency\n",
    "\n",
    "\n",
    "print(f\"The frequency of B4 is {note_frequency('B4'):.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a07db86169a8a86f6e3a64f79bdc5b76",
     "grade": true,
     "grade_id": "cell-1042f067052c84c8",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(note_frequency('A4'), 440)\n",
    "assert np.isclose(note_frequency('A5'), 880)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20e993fc7de9df0fb4aa798dab7d495d",
     "grade": false,
     "grade_id": "cell-e5f34d1de09e8861",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Major chord\n",
    "\n",
    "A major chord is a chord made up of three notes that contains the 1st, 3rd, and 5th notes of a major scale. For example, the notes of a C major chord are the 1st (the root note), 3rd, and 5th notes, which are C (the root note), E, and G.\n",
    "\n",
    "Given the major chord root note, the second note is the major third (root + 4 semitones) and the third note is the perfect fifth (root + 7 semitones).\n",
    "\n",
    "#### A03 - Create a function to compute the frequencies of the 3rd and 5th notes\n",
    "\n",
    "❓The function `major_cord()` computes the frequencies of the 3rd and 5th notes from the root frequency of the cord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0477dd72a17a8cdd3af0c222726f148",
     "grade": false,
     "grade_id": "cell-c9bc957aec7fc4b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def major_chord(rootfreq):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return thirdfreq, fithfreq\n",
    "\n",
    "print(f\"The frequencies of the third and fifth of a C major chord are {major_chord(note_frequency('C4'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbd714397fddae2ca89f59bb2df10432",
     "grade": true,
     "grade_id": "cell-04b8398d6d2fb984",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(major_chord(note_frequency('C4'))[0], note_frequency('E4'))\n",
    "assert np.isclose(major_chord(note_frequency('C4'))[1], note_frequency('G4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "179fc1021859b2962efbc647deab080a",
     "grade": false,
     "grade_id": "cell-04be90bca2156194",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate and play the group's chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca6f2479794739e087d9ccacf75cf847",
     "grade": false,
     "grade_id": "cell-d297321a132f705a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fs = 22050\n",
    "thirdfreq, fithfreq = major_chord(note_frequency(group_note))\n",
    "rootw= 2*np.pi*note_frequency(group_note)/fs\n",
    "thirdw= 2*np.pi*thirdfreq/fs\n",
    "fifthw= 2*np.pi*fithfreq/fs\n",
    "\n",
    "# play the notes of the chord\n",
    "n = np.arange(0, 2*fs)\n",
    "group_chord = np.sin(rootw*n)\n",
    "group_chord[int(fs/2):] += np.sin(thirdw*n[int(fs/2):])\n",
    "group_chord[fs:] += np.sin(fifthw*n[fs:])\n",
    "Audio(group_chord, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ba85edd32b3eb9369b3b2e4e3ca93b6",
     "grade": false,
     "grade_id": "cell-ef1e2cc09d142a46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Frame-based RMS\n",
    "\n",
    "Frame-based root mean square (RMS) is a method of calculating the root mean square (RMS) of an audio signal by analyzing it in a series of frames. Each frame is a sequence of $N$ consecutive samples of the signal. $N$ is commonly referred as the _frame size_.\n",
    "\n",
    "It works by taking each frame of the signal and calculating the RMS value for that specific frame.\n",
    "\n",
    "It works by taking each frame of the signal and calculating the RMS value for that specific frame. \n",
    "\n",
    "It is common to have some overlap between frames. This means that the next frame begins $K$ samples after the beginning of the previous frame. $K$ is referred as the _hop size_ and is often defined as a fraction of the _frame size_ ($K = N/4$, for example).\n",
    "\n",
    "The frame-based RMS can be useful in determining the time changes in the loudness or power of an audio signal, as well as providing a way to compare different signals to one another. This measure is widely used in audio engineering and music production, where it is important to get an accurate measurement of the loudness of a particular recording.\n",
    "\n",
    "#### A04 - Create a function to compute the frame-base RMS\n",
    "\n",
    "❓Use only standard Python or NumPy library functions to create a function that returns a NumPy array with the frame-based RMS values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42f6152096f8aefa7ac0baff119da9b6",
     "grade": false,
     "grade_id": "cell-2661be74ad095d70",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def rms(x, frame_size=0, hop_size=0):\n",
    "    \"\"\"Compute the RMS of a signal in frames.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Input signal.\n",
    "    frame_size : int\n",
    "        Frame size in samples. If 0, the whole signal is used.\n",
    "    hop_size : int\n",
    "        Hop size in samples. If 0, the frame size is divided by 4.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rms : np.ndarray\n",
    "        RMS of the signal in frames.\n",
    "    \"\"\"\n",
    "    if frame_size == 0:\n",
    "        frame_size = len(x)\n",
    "        hop_size = frame_size\n",
    "    if hop_size == 0:\n",
    "        hop_size = frame_size/4\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return fbrms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06a4063b4444643a28b81151db2d848b",
     "grade": true,
     "grade_id": "cell-789c247f1066bde7",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.sum(rms(np.ones(1000), 100, 100)), 10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddb5fa40c58a220f5a4204d8a46342c6",
     "grade": false,
     "grade_id": "cell-edb8111ed108821e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Frame-based RMS of the group's chord\n",
    "\n",
    "A small frame size is good for locating rapid transitions in energy levels, but introduces fluctuations in stable regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e82c6cceebdff2a9a945b2d1061a6123",
     "grade": false,
     "grade_id": "cell-a65561ce66fe560a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "frame_size = 512\n",
    "hop_size = 128\n",
    "# add some silence at the beginning and end of the chord\n",
    "chord = np.concatenate([np.zeros(int(0.2*fs)), group_chord, np.zeros(int(0.2*fs))])\n",
    "rms_chord = rms(chord, frame_size=frame_size, hop_size=hop_size)\n",
    "t = np.arange(len(rms_chord)) * hop_size / fs\n",
    "plt.plot(t, rms_chord)\n",
    "librosa.display.waveshow(chord, sr=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afd211804d3cd189e724f9874be558cb",
     "grade": false,
     "grade_id": "cell-c4824600edd49318",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Frame-based RMS of an audio signal\n",
    "\n",
    "A larger frame size produces a smoother energy envelope but fails to locate fast energy transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d178a7f80275d4790680ac409718916a",
     "grade": false,
     "grade_id": "cell-5f2fc377213be0eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "frame_size = 2048\n",
    "hop_size = 512\n",
    "x, fs = librosa.load(librosa.ex('trumpet'))\n",
    "rms1 = rms(x, frame_size=frame_size, hop_size=hop_size)\n",
    "t = np.arange(len(rms1)) * hop_size / fs\n",
    "plt.plot(t, rms1)\n",
    "librosa.display.waveshow(x, sr=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0fc5d05d99e3b79ebc61b0244f1d702",
     "grade": false,
     "grade_id": "cell-a54b1ba231be91c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Decibels relative to full scale (dBFS)\n",
    "\n",
    "Decibels relative to full scale (dBFS) is a measure of amplitude levels in decibels.\n",
    "\n",
    "If $v$ is the amplitude of the signal that we want to measure and $v_{0}$ a reference amplitude, the amplitude ratio in decibels is:\n",
    "$$\n",
    "L_{dB} = 20 \\log_{10}\\left( \\frac{v}{v_{0}}\\right)\n",
    "$$\n",
    "\n",
    "The measure of decibels realtive to full scale (dBFS) assumes that $v_0$ is the maximum possible value for $v$ such that:\n",
    "$$\n",
    "L_{dBFS}(v_{0}) = 0\\ dB\n",
    "$$\n",
    "\n",
    "When the amplitude is at 50% of the maximum level:\n",
    "$$\n",
    "L_{dBFS}\\left( \\frac{v_{0}}{2} \\right) \\approx -6\\ dB\n",
    "$$\n",
    "\n",
    "Many signals resulting from an analog to digital conversion are represented in an amplitude range of $[-1,1]$, which means that $v_{0}=1$.\n",
    "\n",
    "#### A05 - Create a function to compute the dBFS\n",
    "\n",
    "❓Use only standard Python or NumPy library functions to create a function to convert to dBFS a NumPy array with linear amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f26d622b8b6d0637e7d8c78ef096b72",
     "grade": false,
     "grade_id": "cell-bbadda759a641a56",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dbfs(amplitude):\n",
    "    \"\"\"\n",
    "    Convert amplitude to decibels relative to full scale.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "531e324b7185ba79855b33545b56eb30",
     "grade": true,
     "grade_id": "cell-9840308e1bbc20fe",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(dbfs(1), 0)\n",
    "assert np.isclose(dbfs(0.5), -6, atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c681bad9efc4058880e5b1a9b142b51e",
     "grade": false,
     "grade_id": "cell-f6f8a936ded1f8e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### short-time Fourier transform (STFT)\n",
    "\n",
    "The short-time Fourier transform is a type of Fourier analysis used to determine the frequency content of a signal over short, fixed-length time intervals. It is used in many applications, such as speech processing and musical analysis. The STFT is based on the conventional Fourier transform, but it divides the signal into overlapping segments and then performs a Fourier analysis for each segment. This results in a two-dimensional representation of the signal, where the frequency is on one axis and time on the other. Different resolutions can be obtained for analyzing different aspects of the signal by varying the size and position of the segments.\n",
    "\n",
    "The signal segmentation is performed by multiplying the signal by a window function $w(n)$ that is zero-valued outside a specified interval. For example the rectangular window:\n",
    "$$\n",
    "w_{r}(n) =\n",
    "\\begin{cases}\n",
    "1, & 0 \\le n \\le M-1 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The short-time Fourier transform, $X(n, \\omega)$ is a two-dimensional representation of the signal $x(n)$:\n",
    "$$\n",
    "X(n, \\omega) = \\sum_{m=-\\infty}^{+\\infty} x(n+m)w(m) e^{-j\\omega (n+m)} \n",
    "$$\n",
    "\n",
    "If we use the discrete Fourier transform (DFT):\n",
    "\n",
    "$$\n",
    "X(n,k) = \\sum_{m=0}^{M-1}x(n+m)w(m) e^{-j \\frac{2\\pi}{M}(n+m)},\\ 0\\le k \\le M-1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85fd02b6d196ac3372ad6db7b7d2c67c",
     "grade": false,
     "grade_id": "cell-8c0b671e5d99b0c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Spectrogram of a signal\n",
    "\n",
    "The spectrogram of a time-domain signal is a representation of the magnitude of the [[short-time Fourier transform (STFT)]] ($X(n,k)$) of a signal.\n",
    "\n",
    "To facilitate the analysis of the signal, it is common to use the time axis in seconds or milliseconds and the frequency axis in Hz. The value of the amplitude of the spectrum at each point is represented with a darker color for low values and brighter color for higher values.\n",
    "\n",
    "For better visualization of the entire range of amplitudes, it is frequent to represent them in decibels (dB).\n",
    "\n",
    "The short-time Fourier transform can be computed with the `librosa.stft()` function. The resulting linear amplitudes need to be converted to dB. The function `librosa.display.specshow()` function can then be used to display the spectrogram as a frequency versus time representation of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07e2edecd0c1f910f1e432177fe6437a",
     "grade": false,
     "grade_id": "cell-1f6ebcd8ecedb196",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spectrogram(x, fs, n_fft=2048, win_length=2048, hop_length=512, window='hann'):\n",
    "    D = librosa.stft(x, n_fft=n_fft, win_length=win_length, hop_length=hop_length, window=window)\n",
    "    DAbsdB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    return DAbsdB\n",
    "\n",
    "# Test spectrogram: plot a spectrogram of a trumpet audio\n",
    "\n",
    "x, fs = librosa.load(librosa.ex('trumpet'), duration=3)\n",
    "\n",
    "DAbsdB = spectrogram(x, fs)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "img = librosa.display.specshow(DAbsdB, ax=ax, x_axis='time', y_axis='linear')\n",
    "ax.set(title='Linear-frequency power spectrogram')\n",
    "ax.label_outer()\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "\n",
    "Audio(data=x, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dee7796613525a4ded39275dcbdff08e",
     "grade": false,
     "grade_id": "cell-87a81b5b3a28eed0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Wave and spectrogram visualization\n",
    "\n",
    "It is frequently useful to have a simultaneous view of both the spectrogram and the time domain waveform aligned in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d12eaa0e7954ba64a5dcea82b1271a0",
     "grade": false,
     "grade_id": "cell-69fbc01379db4cda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spec_wave_show(x, fs, tmin=0, tmax=0, n_fft=2048, win_length=2048, hop_length=512, window='hann'):\n",
    "    \"\"\"\n",
    "    Plot a spectrogram and a waveform of a signal x\n",
    "    \"\"\"\n",
    "    if (tmax == 0):\n",
    "        tmax = x.shape[0]/fs\n",
    "    nseg = np.arange(np.floor(tmin*fs), np.ceil(tmax*fs), dtype=int)\n",
    "\n",
    "    D = librosa.stft(x, n_fft=n_fft, win_length=win_length, hop_length=hop_length, window=window)\n",
    "    DAbsdB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,8), nrows=2, sharex=True, gridspec_kw={'height_ratios': [4, 1]})\n",
    "    ax[0].set(xlim=[tmin, tmax])\n",
    "    librosa.display.specshow(DAbsdB, sr=fs, ax=ax[0], x_axis='time', y_axis='linear')\n",
    "    ax[0].set(title='Linear-frequency power spectrogram')\n",
    "    librosa.display.waveshow(x, sr=fs, x_axis='time')\n",
    "    display(Audio(data=x[nseg], rate=fs))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "img, ax = spec_wave_show(x, fs, tmin=0.0, tmax=1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c4000bccf573329482b3a05b9282e0c",
     "grade": false,
     "grade_id": "cell-a5505d4d13e4f896",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Time versus frequency resolution\n",
    "\n",
    "As with the computation of the frame-based RMS, the size of the frame needs to be adjusted depending on the desired time or frequency resolution.\n",
    "\n",
    "The previous spectrogram was computed with the default frame size of 2048 samples. To increase the time resolution we can reduce it to 256 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f9074de85fd0d386ceaad5c79147fa8",
     "grade": false,
     "grade_id": "cell-eb7abe4ed4e60988",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fsize = 256\n",
    "img, ax = spec_wave_show(x, fs, tmin=0.0, tmax=1.9, n_fft=fsize, win_length=fsize, hop_length=fsize//4, window='hann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4deaa6a21ddd93aacb8e36cf6dd7049",
     "grade": false,
     "grade_id": "cell-8a77c6dc75621aef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### A06 - Wideband and narrowband spectrograms\n",
    "\n",
    "❓Compare the differences between the spectrograms with frame sizes of 2048 and 256 samples. Wich one can be considered a narrowband spectrogram? Give an example of an applications for a wideband spectrogram and for a narrowband spectrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86466297b6f4425ea80b3c3de1b24925",
     "grade": true,
     "grade_id": "cell-055ee895b1c1e2ae",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce207b0a1f8125fabf735be156476c36",
     "grade": false,
     "grade_id": "cell-b33703d227e4af7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Autocorrelation\n",
    "\n",
    "Autocorrelation measures how closely related a sequence of values is to itself over successive time intervals. It describes the degree of similarity between observations as a function of the time lag between them. \n",
    "\n",
    "It can be defined as:\n",
    "$$\n",
    "r_{x} (m) = \\sum_{n=-\\infty}^{+\\infty} x(n) x(n+m)\n",
    "$$\n",
    "where the variable $m$ is called _lag_. \n",
    "\n",
    "The autocorrelation sequence is symmetric: $r_{x}(m) = r_{x}(-m)$.\n",
    "\n",
    "The autocorrelation can be used to find the periodicity of a noisy signal since it should be periodicly more similar to itself. This, for example, the case of a tone produced by a musical instrument.\n",
    "\n",
    "The following code computes the autocorrelation of a segment with 256 samples of a stationary region of the second note of the recording  (D5, 587.330 Hz).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1bd3ca2e26fabb13f07f459b0f065d2",
     "grade": false,
     "grade_id": "cell-7eb00a500283bd6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "N = 512\n",
    "tmiddle = 0.294\n",
    "tmin = tmiddle - N/(2*fs)\n",
    "tmax = tmin + N/fs\n",
    "n_seg = np.arange(tmin*fs, tmax*fs, dtype=int)\n",
    "note2 = x[n_seg]\n",
    "\n",
    "\n",
    "acorr = librosa.autocorrelate(note2)\n",
    "\n",
    "time = np.linspace(0,1000*N/fs,N)\n",
    "plt.plot(time, acorr)\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# skip the first 3 samples to locate the index of the second maximum\n",
    "lag = np.argmax(acorr[3:])+3\n",
    "print(f\"D5 frequency: 587.330 Hz\")\n",
    "print(f\"lag = {lag}\")\n",
    "print(f\"period = {1000*lag/fs:.2f} ms\")\n",
    "print(f\"frequency = {fs/lag:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53e7fe5e0008ae8e5396e9cd6c8145de",
     "grade": false,
     "grade_id": "cell-cfa7e6921db00628",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Peak-picking\n",
    "\n",
    "A peak-picking algorithm is an algorithm used to detect local maxima and minima in a set of data. The algorithm typically begins by smoothing the data with a moving average or similar technique. Once the data has been smoothed, the algorithm searches for local maxima and minima, which can be identified by comparing values between adjacent points in the data set. \n",
    "\n",
    "The libROSA library includes the function `librosa.util.peak_pick()` that returns the indexes of the most prominent peaks in the signal.\n",
    "\n",
    "Finding all the peaks of the autocorrelation function provides a better estimate of the fundamental frequency of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "765c7fa5858349a0a740384140976c79",
     "grade": false,
     "grade_id": "cell-f09059653a46623c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "peaks = librosa.util.peak_pick(acorr, pre_max=3, post_max=3, pre_avg=3, post_avg=5, delta=0.8, wait=10)\n",
    "\n",
    "# plot the autocorrelation and location of the peaks\n",
    "time = np.linspace(0,1000*N/fs,N)\n",
    "plt.plot(time, acorr)\n",
    "plt.plot(time[peaks], acorr[peaks], \"x\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1a85259a2df53659c1f5b0d31843dd8",
     "grade": false,
     "grade_id": "cell-a1a48b1d06fa4874",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### A07 - Define a function to compute the pitch of a signal\n",
    "\n",
    "❓Define the contents of the function `pitch()` that provides a better estimate of the fundamental frequência in Hz of the signal `x` by using more harmonic peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60ead1330dd2cffbb3d2d3b23a9b2022",
     "grade": false,
     "grade_id": "cell-b98e1330923c01c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pitch(x, fs):\n",
    "    \"\"\"\n",
    "    Compute the pitch of a signal x\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return f0\n",
    "\n",
    "print(f\"D5 frequency: 587.330 Hz\")\n",
    "print(f\"Frequency using 1st peak: {fs/lag:.2f} Hz\")\n",
    "print(f\"Frequency using pitch() function: {pitch(note2, fs):.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8726377157b852ba7790400c9f62d2c8",
     "grade": true,
     "grade_id": "cell-bad4841e9151f140",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(pitch(note2, fs), 587.330, atol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b202d28c4275bc6baa88720092a7bd5a",
     "grade": false,
     "grade_id": "cell-6f1b4f93dd634125",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Spectral flux\n",
    "\n",
    "Spectral flux is a measure of the change in the magnitude spectrum of a signal over time. Spectral flux measures the difference in energy between two consecutive audio frames and can be used for onset detection or to detect percussive elements or rhythmic transitions. It is also used for sound classification, beat tracking, and instrument detection.\n",
    "\n",
    "The spectral flux can be computed using the temporal evolution of the magnitude spectrogram $| X(n,k) |$ by computing the difference between two consecutive short-time spectra and then summing all positive deviations:\n",
    "\n",
    "$$\n",
    "SF(n) = \\sum_{k=1}^{N/2} H \\left( |X(n,k)| - |X(n-1,k)| \\right)\n",
    "$$\n",
    "\n",
    "where $n$ is the frame number, $k$ the frequency bin index, and $H(\\cdot)$ is the half-wave rectifier function:\n",
    "$$\n",
    "H(x) = \\frac{x+|x|}{2}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53b4b7b2ac92a9b5744504b86e0055b8",
     "grade": false,
     "grade_id": "cell-7a6efc30c7a933d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Onset strength\n",
    "\n",
    "Onset strength is a measure of the energy within an audio signal at the beginning of a sound. It can be used to identify when a sound begins, as well as how loud or soft that sound may be. Onset strength is typically measured in decibels (dB) or in amplitude (or root mean square). It is a useful tool for analyzing and manipulating audio, such as for creating reverberation effects, adjusting dynamic range, or altering the timing of sounds.\n",
    "\n",
    "The function `librosa.onset.onset_strength()` computes a spectral flux onset strength envelope.\n",
    "\n",
    "A peak-picking function can then be used to find the onsets of each note. The \n",
    "`librosa.onset.onset_detect()` function locates note onset events by picking peaks in the onset strength envelope. The _peak_pick_ parameters were chosen by large-scale hyper-parameter optimization over a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "937ac7b78c92bb83e0a69c0c3703d2f0",
     "grade": false,
     "grade_id": "cell-f6751db3809d4510",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute the onset strength envelope\n",
    "onset_env = librosa.onset.onset_strength(y=x, sr=fs)\n",
    "\n",
    "# Use peak picking to obtain actual onsets\n",
    "onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=fs)\n",
    "\n",
    "# Compute and plot the spectrogram\n",
    "D = np.abs(librosa.stft(x))\n",
    "times = librosa.times_like(D)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, figsize=(12, 6), gridspec_kw={'height_ratios': [3, 1, 1]})\n",
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max), x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Power spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "# Plot the onset envelope\n",
    "ax[1].plot(times, onset_env, alpha=0.8, label='Mean (mel)')\n",
    "\n",
    "# Plot the onsets as vertical lines\n",
    "ax[1].vlines(times[onset_frames], 0, onset_env.max(), color='r', alpha=0.9, linestyle='--', label='Onsets')\n",
    "\n",
    "librosa.display.waveshow(x, sr=fs, ax=ax[2])\n",
    "ax[2].vlines(times[onset_frames], -1, 1, color='r', alpha=0.9, linestyle='--', label='Onsets')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa9b3a2c6d333ff2242c6dc7c0b4cb04",
     "grade": false,
     "grade_id": "cell-3a72675bc87d1ec6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Human annotation\n",
    "\n",
    "A human annotator found the following onset locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea64d60c30f1ab4876d87e0e313c7d51",
     "grade": false,
     "grade_id": "cell-5a417acfcfdd088c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "humam_onsets = [0, 0.197047, 0.373982, 0.553917, 0.702099,\n",
    "                0.877512, 1.051384, 1.114890, 1.294825, 1.384577,\n",
    "                1.439750, 1.518568, 1.647638, 1.878505, 2.009869,\n",
    "                2.149115, 2.335652, 2.540256\n",
    "            ]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(12, 6), gridspec_kw={'height_ratios': [3, 1]})\n",
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max), x_axis='time', ax=ax[0])\n",
    "ax[0].vlines(humam_onsets, 0, 1000, color='w', alpha=0.9, linestyle='--', label='Onsets')\n",
    "\n",
    "librosa.display.waveshow(x, sr=fs, ax=ax[1])\n",
    "ax[1].vlines(humam_onsets, -1, 1, color='r', alpha=0.9, linestyle='--', label='Onsets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4ba902c14b8d97f98456818aa559985",
     "grade": false,
     "grade_id": "cell-827e02ea47931ebc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### A08 - Onset detection assessment\n",
    "\n",
    "❓Identify the differences between the results of the automatic onset detector and the human reference. What types of errors exist? What metrics should be used to assess the performance of the onset detector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d8249a3444d0a48bd889fba6e8def3d",
     "grade": true,
     "grade_id": "cell-f12df1b1100e10b6",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa0ebd769646c5a67320a6f026486dd8",
     "grade": false,
     "grade_id": "cell-f1078084c253ace5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Wavetable synthesis\n",
    "\n",
    "Wavetable synthesis is a method for generating a periodic signal by repeated reproduction of a table with the samples of one cycle of the desired waveform.\n",
    "\n",
    "For example, the wavetable $t(n)$ may contain $L$ samples of a single period of the sine function:\n",
    "$$\n",
    "t(n) = \\sin\\left(\\frac{2\\pi}{L}n\\right), 0\\le n \\le L-1\n",
    "$$\n",
    "\n",
    "A periodic signal $s(n)$ can be synthesized by:\n",
    "$$\n",
    "s(n) = t(n\\ \\mathbf{mod}\\ L)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{mod}$ is the modulus operator. This is the same as shifting and concatenating the wavetable:\n",
    "$$\n",
    "s(n) = \\sum_{l=-\\infty}^{+\\infty} t(n-lL)\n",
    "$$\n",
    "\n",
    "With a sampling frequency of $f_s$, this will produce a continuous time signal $s_c(t)$ with frequency $f_s/L$ Hz.\n",
    "\n",
    "To synhthesize a signal with frequency $f$, the wavetable can be re-sampled with the factor $a=L f/f_s$ to produce a periodic signal with the desired frequency:\n",
    "$$\n",
    "s(n) = t(\\lfloor{an}\\rceil\\ \\mathbf{mod}\\ L)\n",
    "$$\n",
    "\n",
    "where $\\lfloor \\cdot \\rceil$ is the round to the nearest integer operator.\n",
    "\n",
    "\n",
    "When $a$ is not an integer, the resulting periodic signal will no be the uniform sampling of a sinusoid. A better approximation can be achieve by interpolation. For example, using linear interpolation:\n",
    "$$\n",
    "s(n) = t(\\lfloor{an}\\rfloor\\ \\mathbf{mod}\\ L) +(an-\\lfloor{an}\\rfloor)\\left[ t(\\lceil{an}\\rceil\\ \\mathbf{mod}\\ L) - t(\\lfloor{an}\\rfloor\\ \\mathbf{mod}\\ L)\\right]\n",
    "$$\n",
    "\n",
    "This can also be computed using a temporary buffer with a signal with a period of L:\n",
    "$$\n",
    "b(n) = \\sum_{l=-\\infty}^{+\\infty} t(n-lL)\n",
    "$$\n",
    "\n",
    "That is then re-sampled to adjust its period to the desired value $N_{0}=aL$:\n",
    "$$\n",
    "s(n) = b(\\lfloor an \\rceil)\n",
    "$$\n",
    "\n",
    "Using linear interpolation:\n",
    "$$\n",
    "s(n) = b(\\lfloor{an}\\rfloor) +(an-\\lfloor{an}\\rfloor)\\left[ b(\\lceil{an}\\rceil) - b(\\lfloor{an}\\rfloor)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acf9606e537f247577650d9aa7bc4555",
     "grade": false,
     "grade_id": "cell-b2293cf6fa7447a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def wavetable_generate(dur, funct):\n",
    "    \"\"\"\n",
    "    Generate a wavetable of len samples using the specified\n",
    "    function that is assumed to have a period of 2pi\n",
    "    \"\"\"\n",
    "    return funct(2*np.pi*np.arange(dur)/dur)\n",
    "\n",
    "\n",
    "def wavetable_synthesis(wavetable, freq, sr, dur):\n",
    "    \"\"\"\n",
    "    Synthesize a periodic signal using a given wavetable.\n",
    "    The wavetable is assumed to have a period of 2pi.\n",
    "    \"\"\"\n",
    "    # N is the number of samples of the synthesized signal\n",
    "    N = int(dur*sr)\n",
    "    # L is the length of the wavetable\n",
    "    L = wavetable.size\n",
    "    # N0 is the desired period in samples of the synthesized signal\n",
    "    N0 = int(sr/freq+0.5)\n",
    "    # buffer signal of period L with the right number of periods\n",
    "    buffer = np.tile(wavetable,int(np.ceil(N/N0)))\n",
    "    # resample buffer to match the desired period with linear interpolation\n",
    "    # using resampling coefficient a=L/N0\n",
    "    s = np.interp(np.arange(0, buffer.size, L/N0), np.arange(buffer.size), buffer)\n",
    "    return s[:N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d959452490dad03da3d99d2879880b0",
     "grade": false,
     "grade_id": "cell-262ac4536f9958b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### A09 - Generate a 440 Hz sine wave\n",
    "\n",
    "❓Use functions `wavetable_generate()` and `wavetable_synthesis()` to produce a one second 440 Hz pure tone using a wavetable of 64 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28c6ca9e5a9f635d43ea5e6cf3c481d6",
     "grade": false,
     "grade_id": "cell-3e203a1b53634e73",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fs = 22050\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.plot(wtable, \".\")\n",
    "Audio(swav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e6cd847f707e2c46885401741a2a310",
     "grade": true,
     "grade_id": "cell-489598a05951cd54",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(len(swav), fs)\n",
    "assert np.isclose(len(wtable), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0c97f988aded384d30600c124cda81e",
     "grade": false,
     "grade_id": "cell-0a8d30c2a7e35de5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### ADSR envelope\n",
    "\n",
    "The envelope of a waveform is one of the sound characteristics that influence the timbre of a sound.  It determines the shape of a waveform and how it changes over time. The envelope is often described in terms of the attack, decay, sustain and release (ADSR) characteristics of a sound. \n",
    "\n",
    "\n",
    "![ADSR model](https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/ADSR_envelope.png/320px-ADSR_envelope.png)\n",
    "\n",
    "The attack is the initial rise in amplitude of a sound or note, the decay is the duration of the gradual decrease in amplitude that follows the attack until it reaches the sustain amplitude, and the release is how fast it fades out after the key is released. Together, these parameters determine how a sound will evolve over time and affect its overall timbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8084c500b5ff31382ebf2ed4f0fd0bd",
     "grade": false,
     "grade_id": "cell-b067cb2f809100dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adsr_envelope(x, attack=0.1, decay=0.2, sustain=0.8, release=0.4, height=1.0):\n",
    "    \"\"\"\n",
    "    Shape a signal with an ADSR envelope.\n",
    "    attack: ratio of the attack phase\n",
    "    decay: ratio of the decay phase\n",
    "    sustain: amplitude ratio of the sustain phase\n",
    "    release: ratio of the release phase\n",
    "    height: amplitude ratio of the whole signal\n",
    "    \"\"\"\n",
    "    shapeA = np.linspace(0, 1, int(attack * len(x)))\n",
    "    shapeD = np.linspace(1, sustain, int(decay * len(x)))\n",
    "    shapeR = np.linspace(sustain, 0, int(release * len(x)))\n",
    "    shapeS = np.ones(len(x)-len(shapeA)-len(shapeD)-len(shapeR)) * sustain\n",
    "    shape = np.concatenate((shapeA, shapeD, shapeS, shapeR))\n",
    "    return x * shape * height\n",
    "\n",
    "\n",
    "fs = 22050\n",
    "duration = 0.2\n",
    "t = np.linspace(0, duration, int(duration*fs))\n",
    "sinew = np.sin(2 * np.pi * 440 * t)\n",
    "shaped_sine = adsr_envelope(sinew)\n",
    "\n",
    "plt.plot(t, shaped_sine)\n",
    "Audio(shaped_sine, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e62f819287700c0c93560b2215380cd3",
     "grade": false,
     "grade_id": "cell-37e5d7213c450219",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Musical score and symbolic representations\n",
    "\n",
    "A musical score also referred to as sheet music, is a visual representation of a musical composition. It is written on a staff consisting of five lines and four spaces. This notation is used to indicate the pitch, duration, meter, and rhythm of the music. It also includes symbols such as clefs, key signatures, time signatures, accidentals, and other marks which help in understanding the music. The score includes instructions for how to perform the piece in terms of dynamics, phrasing, and articulation. The musical score is designed to be read by a musician, such as a composer, a conductor, or an instrumentalist.\n",
    "\n",
    "The development of the electronic music industry raised the need for other forms of musical symbolic representation. At the beginning of the 1980s, the Musical Instrument Digital Interface (MIDI) protocol was developed as an industry standard to allow digital electronic musical instruments to work together. MIDI allowed musicians to record, store, and manipulate musical performances and compositions, as well as control multiple instruments and sounds with one device. This opened up a whole new range of possibilities in terms of creating music electronically.\n",
    "\n",
    "We will use a simple format for symbolic representation where each note event is a python list with `(note, amplitude, duration)` and musical composition is a list of note events. The trumpet sequence can thus be represented as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b604ce769a3e54b3ab8b0333c74a45",
     "grade": false,
     "grade_id": "cell-94fb6bfbc1c60cfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trumpet_note_events = (\n",
    "    ('D#5', 0.4, 0.194047),\n",
    "    ('D5' , 0.5, 0.373982-0.194047),\n",
    "    ('C5' , 0.3, 0.553917-0.373982),\n",
    "    ('A#4', 0.7, 0.702099-0.553917),\n",
    "    ('G#4', 0.2, 0.877512-0.702099),\n",
    "    ('A#4', 0.6, 1.051384-0.877512),\n",
    "    ('B4' , 0.6, 1.114890-1.051384),\n",
    "    ('C5' , 0.4, 1.294825-1.114890),\n",
    "    ('C5', 0.05, 1.384577-1.294825),\n",
    "    ('B4' , 0.5, 1.439750-1.384577),\n",
    "    ('A#4', 0.4, 1.518568-1.439750),\n",
    "    ('G#4', 0.3, 1.647638-1.518568),\n",
    "    ('F4', 0.4, 1.878505-1.647638),\n",
    "    ('F4', 0.05, 2.009869-1.878505),\n",
    "    ('A#4', 0.6, 2.149115-2.009869),\n",
    "    ('A#4', 0.1, 2.335652-2.149115),\n",
    "    ('G#4', 0.5, 2.540256-2.335652),\n",
    "    ('F4', 0.4, 3.000000-2.540256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0f8446884b138ca82dc1c7c5f99dd6e",
     "grade": false,
     "grade_id": "cell-f894cdd357f549a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Synthesis of a musical composition\n",
    "\n",
    "A music synthesizer can convert a symbolic representation of a musical composition into a sound signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8903d3969b219b4d74578e061dfc2d79",
     "grade": false,
     "grade_id": "cell-148087caf0c8d1bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### A10 - Define a function for music synthesis\n",
    "\n",
    "❓Use the functions `wavetable_generate()`, `adsr_envelope()`, `note_frequency()`, and `wavetable_synthesis()` to convert the composition in the list `trumpet_note_events`into a sound signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a068b129a3bad8fc1c035ce3dba906f9",
     "grade": false,
     "grade_id": "cell-7838490a4472969e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def synthesize_composition(composition, fs):\n",
    "    \"\"\"\n",
    "    Synthesize a sound signal based on a symbolic representation of a\n",
    "    musical composition\n",
    "    \"\"\"\n",
    "    out = np.array([])\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return out\n",
    "\n",
    "fs = 22050\n",
    "s_out = synthesize_composition(trumpet_note_events, fs)\n",
    "\n",
    "# Plot the output signal\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "librosa.display.waveshow(s_out, sr=fs, ax=ax)\n",
    "ax.vlines(humam_onsets, -1, 1, color='r', alpha=0.9, linestyle='--', label='Onsets')\n",
    "\n",
    "# Play the output signal\n",
    "Audio(s_out, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d29d30a5a4d28264838a0773483d6395",
     "grade": true,
     "grade_id": "cell-6e3cb931e42498c8",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(len(s_out), 3*fs, atol=200)\n",
    "assert np.isclose(np.max(s_out), 0.7, atol=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "49345cbd358e70c3061d915ca81696aa8f7e07e483518f8ab6512698c1722880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
